# Flash Attention BHND (Triton)

A highly optimized Triton kernel for Flash Attention specifically designed for the **BHND (Batch, Heads, Sequence, Dim)** memory layout.
